{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/I549511/.pyenv/versions/3.10.13/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Users/I549511/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/I549511/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/I549511/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/I549511/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/I549511/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import numpy as np\n",
    "from surprise import Dataset, Reader, SVD, KNNBasic, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.accuracy import rmse\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = 'ml-latest-small'\n",
    "DATA_URL = f\"https://files.grouplens.org/datasets/movielens/${DATA_FILE}.zip\"\n",
    "DATA_DIR = '../data'\n",
    "\n",
    "data_path = os.path.join(DATA_DIR, DATA_FILE, \".zip\")\n",
    "\n",
    "if not os.path.exists(data_path):\n",
    "    urllib.request.urlretrieve(DATA_URL, data_path)\n",
    "    with zipfile.ZipFile(data_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PandaFrames loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "movies_path = os.path.join(DATA_DIR, DATA_FILE, 'movies.csv')\n",
    "ratings_path = os.path.join(DATA_DIR, DATA_FILE, 'ratings.csv')\n",
    "tags_path = os.path.join(DATA_DIR, DATA_FILE, 'tags.csv')\n",
    "links_path = os.path.join(DATA_DIR, DATA_FILE, 'links.csv')\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Lädt die Daten in DataFrames.\n",
    "\n",
    "    Returns:\n",
    "    movies_df : DataFrame\n",
    "        DataFrame mit den Filmen.\n",
    "    ratings_df : DataFrame\n",
    "        DataFrame mit den Bewertungen.\n",
    "    tags_df : DataFrame\n",
    "        DataFrame mit den Tags.\n",
    "    links_df : DataFrame\n",
    "        DataFrame mit den Links.\n",
    "    \"\"\"\n",
    "    movies_df = pd.read_csv(movies_path)\n",
    "    ratings_df = pd.read_csv(ratings_path)\n",
    "    tags_df = pd.read_csv(tags_path)\n",
    "    links_df = pd.read_csv(links_path)\n",
    "    \n",
    "    return movies_df, ratings_df, tags_df, links_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_data_as_dataset(df, reader):\n",
    "    \"\"\"\n",
    "    Lädt die Daten in ein Surprise Dataset.\n",
    "\n",
    "    Parameters:\n",
    "    df : DataFrame\n",
    "        DataFrame mit den Bewertungsdaten.\n",
    "    reader : Reader\n",
    "        Ein Reader-Objekt von Surprise.\n",
    "\n",
    "    Returns:\n",
    "    full_data : Trainset\n",
    "        Das vollständige Trainset.\n",
    "    train_set : list\n",
    "        Die Trainingsdaten.\n",
    "    test_set : list\n",
    "        Die Testdaten.\n",
    "    \"\"\"\n",
    "    data = Dataset.load_from_df(df[['userId', 'movieId', 'rating']], reader)\n",
    "    full_data = data.build_full_trainset()\n",
    "    train_set, test_set = train_test_split(data, test_size=0.2, random_state=42)\n",
    "    return full_data, train_set, test_set\n",
    "\n",
    "# Laden der Daten\n",
    "movies_df, ratings_df, tags_df, links_df = load_data()\n",
    "print(\"PandaFrames loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "What data exploration methods do we need?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-Based\n",
    "This is a function to train a content based recommendation model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_content_based_model(movies, ratings, tags, links) :\n",
    "    print(\"Training content-based model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering - Neighborhood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neighborhood_model(movies, ratings, tags, links) :\n",
    "    print(\"Training neighborhood model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering - Matrix Factorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratings_dataset(ratings_df):\n",
    "    \"\"\"\n",
    "    Erstellt ein Surprise Dataset mit den Bewertungen für jeden Benutzer.\n",
    "\n",
    "    Parameters:\n",
    "    ratings_df : DataFrame\n",
    "        DataFrame mit den Bewertungen.\n",
    "\n",
    "    Returns:\n",
    "    full_rating_dataset : Surprise Dataset\n",
    "        Das vollständige Dataset\n",
    "    train_rating_dataset : Surprise Dataset\n",
    "        Die Trainingsdaten.\n",
    "    test_rating_dataset : Surprise Dataset\n",
    "        Die Testdaten.\n",
    "    \"\"\"\n",
    "    full_rating_dataset, train_rating_dataset, test_rating_dataset = load_data_as_dataset(ratings_df, reader = Reader(line_format=\"user item rating timestamp\", sep=\",\"))\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "    return full_rating_dataset, train_rating_dataset, test_rating_dataset\n",
    "\n",
    "def train_matrix_factorization_model(movies, ratings, tags, links):\n",
    "    \"\"\"\n",
    "    Trainiert ein Matrixfaktorisierungsmodell.\n",
    "\n",
    "    Parameters:\n",
    "    movies : DataFrame\n",
    "        DataFrame mit den Filmen.\n",
    "    ratings : DataFrame\n",
    "        DataFrame mit den Bewertungen.\n",
    "    tags : DataFrame\n",
    "        DataFrame mit den Tags.\n",
    "    links : DataFrame\n",
    "        DataFrame mit den Links.\n",
    "\n",
    "    Returns:\n",
    "    svd_model : SVD\n",
    "        Das trainierte Modell.\n",
    "    \"\"\"\n",
    "    full_rating_dataset, train_rating_dataset, test_rating_dataset = get_ratings_dataset(ratings)\n",
    "    # Use SVD for item-based collaborative filtering\n",
    "    svd_model = SVD(random_state=42)  # Set user_based to False for item-based collaborative filtering\n",
    "\n",
    "    # Train the model on the training set\n",
    "    svd_model.fit(train_rating_dataset)\n",
    "\n",
    "    evaluation = evaluate_model(svd_model, test_rating_dataset)\n",
    "    print(f\"RMSE: {evaluation:.2f}\")\n",
    "\n",
    "    return svd_model\n",
    "\n",
    "def get_prediction_for_user(user_id, movie_id, model):\n",
    "    \"\"\"\n",
    "    Gibt die Vorhersage für einen Benutzer und einen Film zurück.\n",
    "\n",
    "    Parameters:\n",
    "    user_id : int\n",
    "        Die ID des Benutzers.\n",
    "    movie_id : int\n",
    "        Die ID des Films.\n",
    "    model : SVD\n",
    "        Das trainierte Modell.\n",
    "\n",
    "    Returns:\n",
    "    prediction : float\n",
    "        Die Vorhersage.\n",
    "    \"\"\"\n",
    "    prediction = model.predict(user_id, movie_id).est\n",
    "    return prediction\n",
    "\n",
    "def get_top_n_user_recommendations(uid, predictions, n=10):\n",
    "    \"\"\"\n",
    "    Get the top N recommendations for a single user.\n",
    "\n",
    "    Parameters:\n",
    "    uid : int\n",
    "        The user id.\n",
    "    predictions : list\n",
    "        The list of predictions.\n",
    "    n : int, optional\n",
    "        The number of recommendations to return (default is 10).\n",
    "    \"\"\"\n",
    "    user_ratings = [(iid, est) for uid_pred, iid, true_r, est, _ in predictions if uid_pred == uid]\n",
    "    user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "    return user_ratings[:n]\n",
    "\n",
    "def print_top_n_recommendations(predictions, n=10):\n",
    "    \"\"\"\n",
    "    Prints the top N recommendations for each user.\n",
    "\n",
    "    Parameters:\n",
    "    predictions : list\n",
    "        The list of predictions.\n",
    "    n : int, optional\n",
    "        The number of recommendations to return for each user (default is 10).\n",
    "    \"\"\"\n",
    "    users = {uid for uid, _, _, _, _ in predictions}\n",
    "    for uid in users:\n",
    "        user_ratings = get_top_n_user_recommendations(uid, predictions, n)\n",
    "        print(uid, [iid for (iid, _) in user_ratings])\n",
    "\n",
    "def evaluate_model(model, test_set):\n",
    "    \"\"\"\n",
    "    Evaluates the model using RMSE.\n",
    "\n",
    "    Parameters:\n",
    "    model : SVD\n",
    "        The trained model.\n",
    "    test_set : list\n",
    "        The test data.\n",
    "\n",
    "    Returns:\n",
    "    rmse_score : float\n",
    "        The RMSE score.\n",
    "    \"\"\"\n",
    "    predictions = model.test(test_set)\n",
    "    rmse_score = rmse(predictions)\n",
    "\n",
    "    return rmse_score\n",
    "\n",
    "# # Train the matrix factorization model\n",
    "# svd_model = train_matrix_factorization_model(movies_df, ratings_df, tags_df, links_df)\n",
    "\n",
    "# prediction = get_prediction_for_user(1, 1, svd_model)\n",
    "# print(f\"Prediction for user 1 and movie 1: {prediction:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train all Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training content-based model\n",
      "Training neighborhood model\n",
      "Dataset loaded successfully!\n",
      "RMSE: 0.8807\n",
      "RMSE: 0.88\n"
     ]
    }
   ],
   "source": [
    "def train_models(movies, ratings, tags, links) :\n",
    "    content_model = train_content_based_model(movies, ratings, tags, links)\n",
    "    neighborhood_model = train_neighborhood_model(movies, ratings, tags, links)\n",
    "    matrix_model = train_matrix_factorization_model(movies, ratings, tags, links)\n",
    "    return content_model, neighborhood_model, matrix_model\n",
    "\n",
    "movies_df, ratings_df, tags_df, links_df = load_data() \n",
    "\n",
    "content_model, neighborhood_model, matrix_model = train_models(movies=movies_df, ratings=ratings_df, tags=tags_df, links=links_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should return a list of recommended items with their scores\n",
    "# [{'movieId': 1, 'score': 0.5}, {'movieId': 2, 'score': 0.4}, {'movieId': 3, 'score': 0.3}]\n",
    "def make_content_based_recommendations(user, cinema_movies, model) -> []:\n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering - Neighborhood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should return a list of recommended items with their scores\n",
    "# [{'movieId': 1, 'score': 0.5}, {'movieId': 2, 'score': 0.4}, {'movieId': 3, 'score': 0.3}]\n",
    "def make_neighborhood_recommendations(user_rated_movies, cinema_movies, model) -> []:\n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering - Matrix Factorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'movieId': 1, 'score': 4.372892169275733},\n",
       " {'movieId': 2, 'score': 3.6107078434906925},\n",
       " {'movieId': 3, 'score': 3.3263155367563724}]"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def make_matrix_factorization_recommendations(user_rated_movies, movie_id, model) -> int:\n",
    "\n",
    "#     # user = [{'movieId': 1, 'rating': 5}, {'movieId': 2, 'rating': 4}, {'movieId': 3, 'rating': 3}]\n",
    "#     # Extrahiere die Nutzer- und Item-Matrizen\n",
    "#     U = model.pu\n",
    "#     V = model.qi\n",
    "\n",
    "#     # Beispiel-Bewertungen des neuen Nutzers\n",
    "#     new_user_ratings = [(1, 5), (2, 3), (4, 1)]  # (item_id, rating)\n",
    "\n",
    "#     # Extrahiere die relevanten Teile der Item-Matrix und die Bewertungen\n",
    "#     rated_items = [rating[0] for rating in new_user_ratings]\n",
    "#     ratings = [rating[1] for rating in new_user_ratings]\n",
    "\n",
    "#     V_rated = V[rated_items, :]\n",
    "\n",
    "#     # Lineare Regression um den Nutzer-Vektor zu berechnen\n",
    "#     reg = LinearRegression().fit(V_rated, ratings)\n",
    "#     u_new = reg.coef_\n",
    "\n",
    "#     # Berechne die Bewertung für diesen spezifischen Film\n",
    "#     film_score = np.dot(V[movie_id], u_new)\n",
    "\n",
    "#     # Beschränke die Bewertung auf den Bereich von 0 bis 5\n",
    "#     film_score = np.clip(film_score, 0, 5)\n",
    "\n",
    "#     print(f\"Vorhergesagte Bewertung für den Film mit ID {movie_id} für den neuen Nutzer: {film_score}\")\n",
    "#     return 1\n",
    "\n",
    "def find_similar_user(user_rated_movies, model, n_similar=1):\n",
    "    \"\"\"\n",
    "    Find a similar user based on the given user's ratings using a pre-trained model.\n",
    "\n",
    "    Parameters:\n",
    "    user_rated_movies (list of dicts): List of ratings by the user in the form [{'movieId': int, 'rating': float}].\n",
    "    model (AlgoBase): The pre-trained Surprise model.\n",
    "    n_similar (int): The number of similar users to find. Default is 1.\n",
    "\n",
    "    Returns:\n",
    "    list: List of similar user IDs.\n",
    "    \"\"\"\n",
    "    # Map movie IDs to the internal item IDs used by the model\n",
    "    trainset = model.trainset\n",
    "    temp_user_ratings = [(trainset.to_inner_iid(movie['movieId']), movie['rating'])\n",
    "                         for movie in user_rated_movies if movie['movieId'] in trainset._raw2inner_id_items]\n",
    "\n",
    "    # Get the latent factors for the items rated by the temporary user\n",
    "    q_i = np.array([model.qi[item_id] for item_id, _ in temp_user_ratings])\n",
    "    r_ui = np.array([rating for _, rating in temp_user_ratings])\n",
    "\n",
    "    # Calculate the implicit factors (biases can be included if the model uses them)\n",
    "    user_factors = np.linalg.lstsq(q_i, r_ui, rcond=None)[0]\n",
    "\n",
    "    # Calculate the similarity of the temporary user to all other users\n",
    "    similarities = []\n",
    "    for other_inner_user_id in trainset.all_users():\n",
    "        other_user_factors = model.pu[other_inner_user_id]\n",
    "        similarity = np.dot(user_factors, other_user_factors)\n",
    "        similarities.append((similarity, trainset.to_raw_uid(other_inner_user_id)))\n",
    "\n",
    "    # Sort the similarities in descending order and get the top n_similar users\n",
    "    similarities.sort(reverse=True, key=lambda x: x[0])\n",
    "    similar_users = [uid for _, uid in similarities[:n_similar]]\n",
    "    \n",
    "    return similar_users[0]\n",
    "\n",
    "def make_matrix_factorization_recommendations(user_rated_movies, cinema_movies, model) -> []:\n",
    "    \"\"\"\n",
    "    Erstellt Empfehlungen für einen neuen Benutzer basierend auf Matrixfaktorisierung.\n",
    "\n",
    "    Parameters:\n",
    "    user_rated_movies : list\n",
    "        Die Bewertungen des Benutzers.\n",
    "    cinema_movies : list\n",
    "        Die Filme im Kino.\n",
    "    model : SVD\n",
    "        Das trainierte Modell.\n",
    "\n",
    "    Returns:\n",
    "    results : list\n",
    "        Die Empfehlungen.\n",
    "    \"\"\"\n",
    "    similar_user = find_similar_user(user_rated_movies, model, n_similar=1)\n",
    "    print(similar_user)\n",
    "    results = []\n",
    "\n",
    "    for movie in cinema_movies:\n",
    "        res = model.predict(similar_user, movie['movieId'])\n",
    "        results.append({'movieId': movie['movieId'], 'score': res.est})\n",
    "  \n",
    "    return results\n",
    "\n",
    "user_rated_movies = [{'movieId': 1, 'rating': 5}, {'movieId': 2, 'rating': 4}, {'movieId': 3, 'rating': 3}]\n",
    "cinema_movies = [{'movieId': 1}, {'movieId': 2}, {'movieId': 3}]\n",
    "make_matrix_factorization_recommendations(user_rated_movies, cinema_movies, matrix_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_recommendations(user_rated_movies, cinema_movies, content_model, collab_model1, collab_model2) -> []:\n",
    "    content_based_recommendations = make_content_based_recommendations(user_rated_movies, cinema_movies, content_model)\n",
    "    neighborhood_recommendations = make_neighborhood_recommendations(user_rated_movies, cinema_movies, collab_model1)\n",
    "    matrix_factorization_recommendations = make_matrix_factorization_recommendations(user_rated_movies, cinema_movies, collab_model2)\n",
    "\n",
    "    return []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
